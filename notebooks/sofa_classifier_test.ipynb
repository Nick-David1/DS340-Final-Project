{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total dataset size: 489\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_profitable'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ds340/DS340-Final-Project/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_profitable'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     56\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/master_sofa_dataset_final.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClass balance (0=Rejected, 1=Accepted):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mis_profitable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# 3. Dataset Class (Image-Only Mode)\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFurnitureDataset\u001b[39;00m(Dataset):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ds340/DS340-Final-Project/venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ds340/DS340-Final-Project/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'is_profitable'"
     ]
    }
   ],
   "source": [
    "# DS340 Multi-Modal Classification Project Outline\n",
    "#\n",
    "# Goal: Predict if a piece of furniture is profitable ('Accept' vs. 'Reject')\n",
    "# Running image-only mode first (CNN only, no tabular features)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Setup and Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define constants\n",
    "ACCEPTED_CSV_FILE = '../data/sofa data.csv'\n",
    "REJECTED_CSV_FILE = '../data/rejected_sofas_only.csv'\n",
    "NUM_CLASSES = 2  # Binary classification (Accept/Reject)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Data Loading (Image-Only Mode)\n",
    "# ==============================================================================\n",
    "\n",
    "# # Load datasets and assign labels\n",
    "# df_accepted = pd.read_csv(ACCEPTED_CSV_FILE)\n",
    "# df_accepted['is_profitable'] = 1  # Accepted (1)\n",
    "\n",
    "# df_rejected = pd.read_csv(REJECTED_CSV_FILE)\n",
    "# df_rejected['is_profitable'] = 0  # Rejected (0)\n",
    "\n",
    "# # Balance the dataset by randomly sampling rejected examples\n",
    "# n_accepted = len(df_accepted)\n",
    "# df_rejected_balanced = df_rejected.sample(n=n_accepted, random_state=42)\n",
    "\n",
    "# # Combine datasets\n",
    "# df = pd.concat([df_accepted, df_rejected_balanced], ignore_index=True)\n",
    "df = pd.read_csv('../data/master_sofa_dataset_final.csv')\n",
    "print(f\"Total dataset size: {len(df)}\")\n",
    "print(f\"Class balance (0=Rejected, 1=Accepted):\\n{df['decision'].value_counts()}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Dataset Class (Image-Only Mode)\n",
    "# ==============================================================================\n",
    "\n",
    "class FurnitureDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "        self.image_urls = df['photo'].values\n",
    "        self.labels = df['decision'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def load_image_from_url(self, url):\n",
    "        \"\"\"Load image from URL using requests and PIL\"\"\"\n",
    "        try:\n",
    "            # Fetch image from URL\n",
    "            response = requests.get(url)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Convert to RGB if needed (handle PNG, etc.)\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "                \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {url}: {e}\")\n",
    "            # Return a gray placeholder for failed loads (better than pure black)\n",
    "            return Image.new('RGB', (224, 224), color='gray')\n",
    "    \n",
    "    def get_original_image(self, idx):\n",
    "        \"\"\"Get the original image without transforms\"\"\"\n",
    "        img_url = self.image_urls[idx]\n",
    "        return self.load_image_from_url(img_url)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load and transform image\n",
    "        img_url = self.image_urls[idx]\n",
    "        image = self.load_image_from_url(img_url)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        # Create dummy tabular tensor (1-dimensional, all zeros) to maintain interface\n",
    "        tabular = torch.zeros(1, dtype=torch.float32)\n",
    "        \n",
    "        # Get label\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return image, tabular, label\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Data Transforms and Split\n",
    "# ==============================================================================\n",
    "\n",
    "# Standard ImageNet normalization\n",
    "IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGE_MEAN, std=IMAGE_STD)\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGE_MEAN, std=IMAGE_STD)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42, stratify=df['decision'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, stratify=df_temp['decision'])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FurnitureDataset(df_train, train_transforms)\n",
    "val_dataset = FurnitureDataset(df_val, test_transforms)\n",
    "test_dataset = FurnitureDataset(df_test, test_transforms)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Model Architecture (Image-Only Mode)\n",
    "# ==============================================================================\n",
    "\n",
    "class ImageOnlyClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        \n",
    "        # Freeze backbone\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Replace final fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, tabular=None):\n",
    "        # Ignore tabular input (maintain interface compatibility)\n",
    "        return self.resnet(image)\n",
    "\n",
    "# Initialize model\n",
    "model = ImageOnlyClassifier(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Training Setup\n",
    "# ==============================================================================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only optimize the final classifier layers\n",
    "optimizer = torch.optim.Adam(model.resnet.fc.parameters(), lr=LEARNING_RATE)\n",
    "num_epochs = 10\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for images, _, labels in loader:  # Ignore tabular data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # No tabular input needed\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    return avg_loss, f1\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _, labels in loader:  # Ignore tabular data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # No tabular input needed\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def analyze_errors(model, dataset, device, num_examples=10):\n",
    "    \"\"\"\n",
    "    Analyze and display misclassified examples from the dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (image, _, label) in enumerate(dataloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            if predicted != label:\n",
    "                orig_image = dataset.get_original_image(idx)\n",
    "                misclassified.append({\n",
    "                    'image': orig_image,\n",
    "                    'true': label.item(),\n",
    "                    'pred': predicted.item(),\n",
    "                    'url': dataset.image_urls[idx]\n",
    "                })\n",
    "                \n",
    "            if len(misclassified) >= num_examples:\n",
    "                break\n",
    "    \n",
    "    # Plot misclassified examples\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, example in enumerate(misclassified[:num_examples]):\n",
    "        axes[idx].imshow(example['image'])\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'True: {\"Accept\" if example[\"true\"] == 1 else \"Reject\"}\\nPred: {\"Accept\" if example[\"pred\"] == 1 else \"Reject\"}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print URLs of misclassified images\n",
    "    print(\"\\nMisclassified Image URLs:\")\n",
    "    for example in misclassified[:num_examples]:\n",
    "        print(f\"True: {'Accept' if example['true'] == 1 else 'Reject'}, Predicted: {'Accept' if example['pred'] == 1 else 'Reject'}\")\n",
    "        print(f\"URL: {example['url']}\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Training Loop\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Starting Training (Image-Only Mode) ---\")\n",
    "best_val_f1 = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    val_loss, val_acc, val_f1 = evaluate_model(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_image_only_model.pth')\n",
    "        print(\"Model saved (New best F1 score)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. Final Evaluation\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Final Test Evaluation ---\")\n",
    "model.load_state_dict(torch.load('best_image_only_model.pth'))\n",
    "test_loss, test_acc, test_f1 = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Analyze misclassified examples from test set\n",
    "print(\"\\n--- Analyzing Misclassified Examples ---\")\n",
    "analyze_errors(model, test_dataset, DEVICE)\n",
    "\n",
    "# Next steps:\n",
    "# 1. Try different augmentation strategies\n",
    "# 2. Experiment with other pre-trained models (MobileNet, EfficientNet)\n",
    "# 3. Add tabular features back once image pipeline is working"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
